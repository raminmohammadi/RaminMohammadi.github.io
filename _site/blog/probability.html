<!doctype html>

<html class="no-js" lang="en">

<head>


	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

	Machine Learning For Engineering

	Personal Theme by https://jekyllthemes.io
	Premium + free Jekyll themes for your blog or website.

	- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->


	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

	<!-- Page Info -->
	<link rel="shortcut icon" href="/images/favicon.png">
	<title>Probabilities and Statistics – Machine Learning For Engineering</title>
	<meta name="description" content="">

	<!-- Twitter Card -->
	<meta name="twitter:card" content="summary_large_image">
	<meta name="twitter:title" content="Probabilities and Statistics – Machine Learning For Engineering">
	<meta name="twitter:description" content="">
	<meta name="twitter:image:src" content="http://localhost:4000/images/Posts/Probabilities/demo/demo-square.jpg">

	<!-- Facebook OpenGraph -->
	<meta property="og:title" content="Probabilities and Statistics – Machine Learning For Engineering" />
	<meta property="og:description" content="" />
	<meta property="og:image" content="http://localhost:4000/images/Posts/Probabilities/demo/demo-square.jpg" />

	
	<!-- Font Embed Code -->
	<link href="https://fonts.googleapis.com/css?family=Muli:300,400,600,700" rel="stylesheet">
	

	<!-- Styles -->
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="/css/style.css">
	
	<!-- Icons -->
	<script defer src="https://use.fontawesome.com/releases/v5.1.1/js/solid.js" integrity="sha384-GXi56ipjsBwAe6v5X4xSrVNXGOmpdJYZEEh/0/GqJ3JTHsfDsF8v0YQvZCJYAiGu" crossorigin="anonymous"></script>
	<script defer src="https://use.fontawesome.com/releases/v5.1.1/js/brands.js" integrity="sha384-0inRy4HkP0hJ038ZyfQ4vLl+F4POKbqnaUB6ewmU4dWP0ki8Q27A0VFiVRIpscvL" crossorigin="anonymous"></script>
	<script defer src="https://use.fontawesome.com/releases/v5.1.1/js/fontawesome.js" integrity="sha384-NY6PHjYLP2f+gL3uaVfqUZImmw71ArL9+Roi9o+I4+RBqArA2CfW1sJ1wkABFfPe" crossorigin="anonymous"></script>

	
	<!-- Custom Styles -->
	<style></style>
	

	
	<!-- Analytics Code -->
	
	

	
	<!-- Extra Header JS Code -->
	
	
	
</head>


<body class="loading ajax-loading" data-site-url="http://localhost:4000" data-page-url="/blog/probability">


	<header class="header">

	<div class="wrap">

		
		<a href="/" class="header__title">
			Machine Learning For Engineering
		</a>
		

		<div class="menu">
			<div class="menu__toggle js-menu-toggle">
				<div class="menu__toggle__icon"><span></span></div>
			</div>
			<div class="menu__wrap">
				<ul class="menu__list">
					
					<li class="menu__list__item">
						<a href="/blog/" class="menu__list__item__link">Blog</a>
					</li>
					
					<li class="menu__list__item">
						<a href="/" class="menu__list__item__link">Projects</a>
					</li>
					
					<li class="menu__list__item">
						<a href="/contact" class="menu__list__item__link">Contact</a>
					</li>
					
					<li class="menu__list__item">
						<a href="/about/" class="menu__list__item__link">Meet Our Team</a>
					</li>
					
				</ul>
			</div>
		</div>

	</div>

</header>


	<div class="loader"><svg width="120" height="30" viewBox="0 0 120 30" xmlns="http://www.w3.org/2000/svg"><circle cx="15" cy="15" r="15"><animate attributeName="r" from="15" to="15" begin="0s" dur="0.8s" values="15;9;15" calcMode="linear" repeatCount="indefinite" /><animate attributeName="fill-opacity" from="1" to="1" begin="0s" dur="0.8s" values="1;.5;1" calcMode="linear" repeatCount="indefinite" /></circle><circle cx="60" cy="15" r="9" fill-opacity="0.3"><animate attributeName="r" from="9" to="9" begin="0s" dur="0.8s" values="9;15;9" calcMode="linear" repeatCount="indefinite" /><animate attributeName="fill-opacity" from="0.5" to="0.5" begin="0s" dur="0.8s" values=".5;1;.5" calcMode="linear" repeatCount="indefinite" /></circle><circle cx="105" cy="15" r="15"><animate attributeName="r" from="15" to="15" begin="0s" dur="0.8s" values="15;9;15" calcMode="linear" repeatCount="indefinite" /><animate attributeName="fill-opacity" from="1" to="1" begin="0s" dur="0.8s" values="1;.5;1" calcMode="linear" repeatCount="indefinite" /></circle></svg></div>

	<div class="page-loader"></div>

	
	<div class="page">

		<div class="page__content" data-page-title="Probabilities and Statistics – Machine Learning For Engineering">

			<section class="hero hero--single">

	<div class="hero__image" style="background-image: url(/images/Posts/Probabilities/demo/demo-square.jpg)">
		<div class="hero__overlay"></div>
	</div>

	<div class="wrap">

		<h1>Probabilities and Statistics</h1>
		<p>19 June 2022</p>

	</div>

</section>

<section class="single">

	<div class="wrap">

		<article class="single-post">

			<h1 id="probability-and-statistics">Probability and Statistics</h1>
<blockquote>
  <p><cite>Learn Statistics and think Probabilities</cite></p>
</blockquote>

<p>The real-world data is often noisy with some true underlying signal. By applying Machine Learning, we hope to identify the signal from the noise. We require a language for quantifying “noise” or uncertainty. Quantification of uncertainty is the realm of Probability Theory.</p>

<p><img src="/images/Posts/Probabilities/0.jpg" style="display: block;          margin-left: auto;         margin-right: auto; height:250px;width:450px" /></p>

<h2 id="table-of-contents">Table of contents</h2>
<ol>
  <li><a href="#probability">Probability</a><br />
 1.1 <a href="#basic_terminology">Basic Terminology</a><br />
 1.2 <a href="#marginal_probability">Marginal Probability</a><br />
 1.3 <a href="#joint_probability">Joint Probability</a><br />
 1.4 <a href="#conditional_probability">Conditional Probability</a><br />
 1.5 <a href="#bayes_rule">Bayes Rule/Theorem</a><br />
 1.6 <a href="#references">References</a><br /></li>
  <li><a href="#statistics">Statistics</a><br />
 2.1 <a href="#population">Population</a><br />
 2.2 <a href="#sample">Sample</a><br />
 2.3 <a href="#mean">Mean</a><br />
 2.4 <a href="#variance">Variance</a><br />
 2.5 <a href="#std">Standard Deviation</a><br />
 2.6 <a href="#normal_distribution">Normal/Gaussian Distribution</a><br /></li>
</ol>

<h2 id="1-probability-">1. Probability <a name="probability"></a></h2>

<p><strong><em>Probability</em></strong> is the branch of mathematics that concerns the study of <em>uncertainty</em> i.e, how likely an event is to occur. In simple terms, the probability is a number that reflects the chance or likelihood that a particular event will occur.</p>
<ul>
  <li>Probabilities can be expressed as proportions that range from 0 to 1, and they can also be expressed as percentages ranging from 0% to 100%.</li>
  <li>A probability of 0 indicates that there is no chance that a particular event will occur, whereas a probability of 1 indicates that an event is certain to occur.</li>
  <li>A probability of 0.45 (45%) indicates that there are 45 chances out of 100 of the event occurring.</li>
</ul>

<p><img src="/images/Posts/Probabilities/1.svg" style="display: block;          margin-left: auto;         margin-right: auto; height:250px;width:450px" /></p>

<h3 id="11-basic-terminology-">1.1 Basic Terminology <a name="basic_terminology"></a></h3>

<p><strong>1. Sample Space</strong><br />
The set of all possible outcomes or results of an experiment is called <strong><em>Sample Space</em></strong>.</p>
<ul>
  <li>It is commonly denoted by the labels $S$ or $\Omega$.</li>
</ul>

<p><strong>2. Event</strong><br />
A subset of the sample space is an <strong><em>Event</em></strong>. If the outcome of an experiment is included in this subset, then the event has occurred.</p>
<ul>
  <li>It is denoted by $E$</li>
  <li>The Probability of event E is denoted as $P(E)$.</li>
</ul>

<script type="math/tex; mode=display">\large P(E) = \frac{\textrm{Number of outcomes in event}}{\textrm{Number of outcomes  in sample space}}</script>

<p>Example-1:</p>

<ul>
  <li><em>Experiment:</em> Tossing a single coin</li>
  <li><em>Sample space:</em> ${H,T}$
    <ul>
      <li>$H$ means that the coin was heads</li>
      <li>$T$ means that the coin was tails</li>
    </ul>
  </li>
  <li><em>Possible Events:</em>
    <ol>
      <li>$E={H}$</li>
      <li>$E={T}$</li>
    </ol>
  </li>
  <li><em>Probability of Events:</em>
    <ol>
      <li>$P(E=H) = \frac{1}{2}$</li>
      <li>$P(E=T) = \frac{1}{2}$</li>
    </ol>
  </li>
</ul>

<h2 id="12-marginal-probability-">1.2 Marginal Probability <a name="marginal_probability"></a></h2>
<p><strong><em>Marginal Probability</em></strong> is the probability of occurrence of a single event.</p>
<ul>
  <li>It may be thought of as an unconditional probability. It is not conditioned on another event.</li>
  <li>The marginal probability of an event A is denoted as $P(A)$.</li>
  <li>E.g:
    <ol>
      <li>The probability that a card drawn is red i.e, $P(red) = 0.5$</li>
      <li>The probability that a card drawn is a 4 i/e, $P(four) = 1/13$</li>
    </ol>
  </li>
</ul>

<h2 id="13-joint-probability-">1.3 Joint Probability <a name="joint_probability"></a></h2>
<p><strong><em>Joint probability</em></strong> is the probability that two
events will occur simultaneously.</p>
<ul>
  <li>The joint probability of two events A and B is denoted as $P(A,B)$ or $P(A \cap B)$.</li>
</ul>

<p><img src="/images/Posts/Probabilities/joint-probability.png" style="display: block;          margin-left: auto;         margin-right: auto; height:250px;width:300px" /></p>

<h2 id="14-conditional-probability-">1.4 Conditional Probability <a name="conditional_probability"></a></h2>

<p><strong><em>Conditional probability</em></strong>  is a measure of the probability of an event occurring, given that another event (by assumption, presumption, assertion, or evidence) has already occurred.</p>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>If the event of interest is A and the event B is known or assumed to have occurred, “the conditional probability of A given B”, or “the probability of A under the condition B”, is usually written as $P(A</td>
          <td>B)$ or occasionally $P_B(A)$.</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>This can also be understood as the fraction of probability B that intersects with A.</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>It is important to note that $P(A</td>
          <td>B)$ is <strong>not the same</strong> as $P(B</td>
          <td>A)$.</td>
        </tr>
        <tr>
          <td>$$\large P(A</td>
          <td>B) = \frac{P(A \cap B)}{P(B)}$$</td>
          <td> </td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<h2 id="15-bayes-ruletheorem-">1.5 Bayes Rule/Theorem <a name="bayes_rule"></a></h2>
<p><strong><em>Bayes Rule/Theorem</em></strong> tells us how to calculate conditional probability with the information we already have. It is a mathematical rule that describes how to update a belief, given some evidence. In other words – it describes <em>the act of learning</em>.</p>

<ul>
  <li>Equation:</li>
</ul>

<p><img src="/images/Posts/Probabilities/bt.png" style="display: block;          margin-left: auto;         margin-right: auto; height:250px;width:450px" /></p>

<p>There are four parts:</p>

<ol>
  <li><strong>Posterior probability</strong> (updated probability after the evidence is considered)</li>
  <li><strong>Prior probability</strong> (the probability before the evidence is considered)</li>
  <li><strong>Likelihood</strong> (probability of the evidence, given the belief is true)</li>
  <li><strong>Marginal probability</strong> (probability of the evidence, under any circumstance)</li>
</ol>

<p><img src="/images/Posts/Probabilities/bayes-rule.png" style="display: block;          margin-left: auto;         margin-right: auto; height:250px;width:600px" /></p>

<h3 id="16-references-">1.6 References <a name="references"></a></h3>
<ul>
  <li><a href="https://www.youtube.com/playlist?list=PLC58778F28211FA19">Probability basics</a></li>
  <li><a href="https://www.freecodecamp.org/news/bayes-rule-explained/">Bayes Rule - for beignners</a></li>
  <li><a href="https://www.youtube.com/watch?v=9wCnvr7Xw4E">Bayes Theorem - Clearly Explained</a></li>
  <li><a href="https://www.youtube.com/watch?v=HZGCoVF3YvM">Bayes theorem, the geometry of changing beliefs</a></li>
</ul>

<h2 id="2-statistics-">2. Statistics <a name="statistics"></a></h2>

<p>While <em>Probability</em> deals with quantifying uncertainty and predicting the likelihood of future events, <strong><em>Statistics</em></strong> involves the analysis of the frequency of past events. It concerns the collection, organization, displaying, analysis, interpretation, and presentation of data. In statistics, we apply probability(probability theory) to draw conclusions from data.</p>

<h3 id="21-population-">2.1 Population <a name="population"></a></h3>

<p>A <strong><em>Population</em></strong> is a representative sample of a larger group of people (or even things) with one or more characteristics in common.</p>
<ul>
  <li>It is denoted by $N$</li>
</ul>

<h3 id="22-sample-">2.2 Sample <a name="sample"></a></h3>

<p>A <strong><em>Sample</em></strong> is the selection of a subset of individuals from within a statistical population to estimate the characteristics of the whole population.</p>
<ul>
  <li>It is denoted by $n$</li>
</ul>

<h3 id="23-mean-">2.3 Mean <a name="mean"></a></h3>

<p>The <strong><em>Mean</em></strong> summarizes an entire dataset with a single number representing the data’s center point or typical value. It is also known as the <strong>arithmetic average</strong>, and it is one of several measures of central tendency.</p>
<ul>
  <li>Population mean is denoted by $\mu$ while sample mean is denoted by $\bar{X}$</li>
</ul>

<p><img src="/images/Posts/Probabilities/mean.png" style="display: block;          margin-left: auto;         margin-right: auto; height:250px;width:450px" /></p>

<h3 id="24-variance-">2.4 Variance <a name="variance"></a></h3>

<p><strong><em>Variance</em></strong> is a measure of variability. It is calculated by taking the average of squared deviations from the mean. Variance tells you the degree of spread in your data set. The more spread the data, the larger the variance is in relation to the mean.</p>
<ul>
  <li>Population variance is denoted by $ \sigma^2$ while sample variance is denoted by $s^2$</li>
</ul>

<p><img src="/images/Posts/Probabilities/variance.png" style="display: block;          margin-left: auto;         margin-right: auto; height:250px;width:450px" /></p>

<h3 id="25-standard-deviation-">2.5 Standard Deviation <a name="std"></a></h3>

<p>The <strong><em>Standard Deviation</em></strong> is a statistic that measures the dispersion of a dataset relative to its mean and is calculated as the square root of the variance.</p>

<ul>
  <li>Population standard deviation is denoted by $\sigma$ while sample standard deviation is denoted by $s$.</li>
</ul>

<h3 id="26-normalgaussian-distribution-">2.6 Normal/Gaussian Distribution <a name="normal_distribution"></a></h3>
<p>A <strong><em>Normal Distribution</em></strong> is a continuous probability distribution of data points that appears as a bell curve when graphed using a line graph or histogram. It also goes by the name <em>Gauss distribution</em>, <em>Gaussian distribution</em>, and <em>Laplace-Gauss distribution</em>.</p>

<ul>
  <li>It is a <em>parametric distribution</em>, meaning - the information about the distribution of the population is known and is based on a fixed set of parameters, here $\mu$ and $\sigma$.</li>
  <li>
    <p>The general form of its probability density function is</p>

    <script type="math/tex; mode=display">\LARGE f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{1}{2} (\frac{x-\mu}{\sigma})^2 }</script>
  </li>
  <li>The parameters $\mu$ and $\sigma$ are also called <strong><em>location</em></strong> and <strong><em>scale</em></strong> parameters respectively.</li>
</ul>

<p>Compared to other probability distributions, a normal distribution has several notable properties.</p>

<ol>
  <li><strong>Its graph has a distinctive symmetrical shape</strong> - A normal distribution curve appears symmetrically in the shape of a bell.</li>
  <li><strong>It is characterized by equal values</strong> - The mean, median, and mode of its data set will all be the same number.</li>
  <li><strong>Data distribution is equally split</strong> - Regardless of sample size and the sample mean, half the data points will be below the mean, and half the data points will be above the mean.</li>
  <li><strong>It divides its data using standard deviations</strong> - A standard deviation is a measurement of how far away a data point is from the mean. The skewness of a data point will depend on the number of standard deviations it falls from the sample mean.</li>
  <li><strong>The distribution of data follows an empirical rule of normal probability</strong>  - With a normal distribution of data, 99.7 percent of all data points fall within three standard deviations from the mean in either direction. The first standard deviation of the mean covers 34.1 percent of all data points above the mean and 34.1 percent of all data points below the mean. The second standard deviation encompasses an additional 13.6 percent of data points above the mean and another 13.6 percent below the mean. The third standard deviation includes 2.1 percent of data points in either direction—both at the very top of the scale and the very bottom of the scale. This means you could fall on the ninety-ninth percentile of sample size and still be within three standard deviations of the mean. You have to be a true outlier, or special case, to go beyond three standard deviations.</li>
  <li><strong>The total area under the curve has a value of one</strong> - If you were to calculate the total area under a normal distribution curve, its value would equal one unit of measure.</li>
</ol>

<p><img src="/images/Posts/Probabilities/normal-distribution.png" style="display: block;          margin-left: auto;         margin-right: auto; height:350px;width:650px" /></p>

<h2 id="references">References</h2>
<hr />
<p><a href="https://www.youtube.com/watch?v=rzFX5NWojp0">Gaussian Distribution - Clearly Explained</a></p>



		</article>

	</div>

</section>

		</div>

	</div>


	<footer class="footer">

	<div class="wrap">

		<p class="footer__text"></p>

		<div class="footer__copyright">
			<span>© 2022 Machine Learning For Engineering</span>
			<a href="https://jekyllthemes.io" target="_blank">Jekyll Themes</a>
		</div>

		<ul class="socials">
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	<li class="socials__item">
		<a href="https://medium.com/@mohammadi.r" target="_blank" class="socials__item__link" title="Medium">
			<i class="fab fa-medium" aria-hidden="true"></i>
		</a>
	</li>
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	<li class="socials__item">
		<a href="https://www.linkedin.com/in/ramin-mohammadi-ml/" target="_blank" class="socials__item__link" title="Linkedin">
			<i class="fab fa-linkedin" aria-hidden="true"></i>
		</a>
	</li>
	
	
</ul>

	</div>

</footer>


	<!-- Javascript Assets -->
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script src="/js/plugins-min.js"></script>
	<script src="/js/personal-min.js"></script>

	
	<!-- Extra Footer JS Code -->
	
	


</body>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


</html>