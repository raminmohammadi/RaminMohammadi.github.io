<!doctype html>

<html class="no-js" lang="en">

<head>


	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

	ML with Ramin

	Personal Theme by https://jekyllthemes.io
	Premium + free Jekyll themes for your blog or website.

	- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->


	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

	<!-- Page Info -->
	<link rel="shortcut icon" href="/images/favicon.png">
	<title>Attention Mechanism – ML with Ramin</title>
	<meta name="description" content="">

	<!-- Twitter Card -->
	<meta name="twitter:card" content="summary_large_image">
	<meta name="twitter:title" content="Attention Mechanism – ML with Ramin">
	<meta name="twitter:description" content="">
	<meta name="twitter:image:src" content="http://localhost:4000/images/demo/demo-square.jpg">

	<!-- Facebook OpenGraph -->
	<meta property="og:title" content="Attention Mechanism – ML with Ramin" />
	<meta property="og:description" content="" />
	<meta property="og:image" content="http://localhost:4000/images/demo/demo-square.jpg" />

	
	<!-- Font Embed Code -->
	<link href="https://fonts.googleapis.com/css?family=Muli:300,400,600,700" rel="stylesheet">
	

	<!-- Styles -->
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="/css/style.css">
	
	<!-- Icons -->
	<script defer src="https://use.fontawesome.com/releases/v5.1.1/js/solid.js" integrity="sha384-GXi56ipjsBwAe6v5X4xSrVNXGOmpdJYZEEh/0/GqJ3JTHsfDsF8v0YQvZCJYAiGu" crossorigin="anonymous"></script>
	<script defer src="https://use.fontawesome.com/releases/v5.1.1/js/brands.js" integrity="sha384-0inRy4HkP0hJ038ZyfQ4vLl+F4POKbqnaUB6ewmU4dWP0ki8Q27A0VFiVRIpscvL" crossorigin="anonymous"></script>
	<script defer src="https://use.fontawesome.com/releases/v5.1.1/js/fontawesome.js" integrity="sha384-NY6PHjYLP2f+gL3uaVfqUZImmw71ArL9+Roi9o+I4+RBqArA2CfW1sJ1wkABFfPe" crossorigin="anonymous"></script>

	
	<!-- Custom Styles -->
	<style></style>
	

	
	<!-- Analytics Code -->
	
	

	
	<!-- Extra Header JS Code -->
	
	
	
</head>


<body class="loading ajax-loading" data-site-url="http://localhost:4000" data-page-url="/blog/attention">


	<header class="header">

	<div class="wrap">

		
		<a href="/" class="header__title">
			ML with Ramin
		</a>
		

		<div class="menu">
			<div class="menu__toggle js-menu-toggle">
				<div class="menu__toggle__icon"><span></span></div>
			</div>
			<div class="menu__wrap">
				<ul class="menu__list">
					
					<li class="menu__list__item">
						<a href="/about/" class="menu__list__item__link">About us</a>
					</li>
					
					<li class="menu__list__item">
						<a href="/ml/" class="menu__list__item__link">Machine Learning</a>
					</li>
					
					<li class="menu__list__item">
						<a href="/mlops/" class="menu__list__item__link">MLOps</a>
					</li>
					
				</ul>
			</div>
		</div>

	</div>

</header>


	<div class="loader"><svg width="120" height="30" viewBox="0 0 120 30" xmlns="http://www.w3.org/2000/svg"><circle cx="15" cy="15" r="15"><animate attributeName="r" from="15" to="15" begin="0s" dur="0.8s" values="15;9;15" calcMode="linear" repeatCount="indefinite" /><animate attributeName="fill-opacity" from="1" to="1" begin="0s" dur="0.8s" values="1;.5;1" calcMode="linear" repeatCount="indefinite" /></circle><circle cx="60" cy="15" r="9" fill-opacity="0.3"><animate attributeName="r" from="9" to="9" begin="0s" dur="0.8s" values="9;15;9" calcMode="linear" repeatCount="indefinite" /><animate attributeName="fill-opacity" from="0.5" to="0.5" begin="0s" dur="0.8s" values=".5;1;.5" calcMode="linear" repeatCount="indefinite" /></circle><circle cx="105" cy="15" r="15"><animate attributeName="r" from="15" to="15" begin="0s" dur="0.8s" values="15;9;15" calcMode="linear" repeatCount="indefinite" /><animate attributeName="fill-opacity" from="1" to="1" begin="0s" dur="0.8s" values="1;.5;1" calcMode="linear" repeatCount="indefinite" /></circle></svg></div>

	<div class="page-loader"></div>

	
	<div class="page">

		<div class="page__content" data-page-title="Attention Mechanism – ML with Ramin">

			<section class="hero hero--single">

	<div class="hero__image" style="background-image: url(/images/demo/demo-square.jpg)">
		<div class="hero__overlay"></div>
	</div>

	<div class="wrap">

		<h1>Attention Mechanism</h1>
		<!-- <p>26 March 2022</p> -->
		<p align="right"><b>- Ramin Mohammadi<b></p>
			
	</div>

</section>

<section class="single">

	<div class="wrap">

		<article class="single-post">

			<h2 id="introduction">Introduction</h2>

<p>Attention mechanisms have revolutionized the field of deep learning, especially in natural language processing (NLP), computer vision, and speech recognition. An attention mechanism allows a model to focus on different parts of the input, depending on their relevance to the output. In other words, it helps the model to selectively attend to different parts of the input, rather than processing it as a whole.</p>

<p>In this blog post, we will explain the attention mechanism in detail, including the mathematical expressions and formulas. We will also provide a full numerical example to help readers understand how attention works.</p>

<h2 id="attention-mechanism">Attention Mechanism</h2>

<p>An attention mechanism is a way to compute a weighted sum of input vectors based on their relevance to a query. Given a query q and a set of input vectors ${x_1, x_2, …, x_n}$, the attention mechanism computes a set of attention weights ${α_1, α_2, …, α_n}$, where each weight α_i represents the relevance of the i-th input vector x_i to the query q. The attention mechanism then computes the weighted sum of the input vectors as follows:</p>

<p>\begin{equation}
c = α_1 * x_1 + α_2 * x_2 + … + α_n * x_n
\end{equation}</p>

<p>The resulting vector $c$ is called the context vector, which represents the attended information from the input. The attention weights $α_i$ are typically computed using a function that takes the query q and the i-th input vector $x_i$ as inputs and produces a scalar value as output. This function is called the attention score function.</p>

<h3 id="attention-score-function">Attention Score Function</h3>

<p>The attention score function is used to compute the relevance of an input vector $x_i$ to a query $q$. There are several ways to define the attention score function, but one of the most common approaches is the dot product attention, which is defined as follows:</p>

<p>\begin{equation}
score(q, x_i) = q * x_i
\end{equation}</p>

<p>where * denotes the dot product. In other words, the attention score is simply the dot product between the query $q$ and the $i$-th input vector $x_i$.</p>

<p>Another common approach is the additive attention, which is defined as follows:</p>

<p>\begin{equation}
score(q, x_i) = v_a * tanh(W_a * q + U_a * x_i)
\end{equation}</p>

<p>where $W_a$ and $U_a$ are weight matrices, $v_a$ is a weight vector, and tanh is the hyperbolic tangent function. In this case, the attention score is computed by applying a non-linear transformation to a concatenation of the query q and the i-th input vector x_i, followed by a dot product with a weight vector $v_a$.</p>

<h3 id="softmax-function">Softmax Function</h3>

<p>Once the attention scores are computed, they are transformed into attention weights using the softmax function. The softmax function is a widely used function that takes a vector of arbitrary real numbers and outputs a probability distribution over the vector elements. Specifically, the softmax function is defined as follows:</p>

<p>\begin{equation}
softmax(z)_i = exp(z_i) / sum_j(exp(z_j))
\end{equation}</p>

<p>where $z$ is the input vector and e is the base of the natural logarithm. In other words, the softmax function computes the exponential of each element of the input vector, normalizes the resulting vector to have a sum of one, and outputs the resulting vector as the attention weights.</p>

<h2 id="numerical-example">Numerical Example</h2>

<p>To illustrate how the attention mechanism works, let’s consider a simple example of machine translation, where we want to translate a sentence from French to English. Suppose the input sentence in French is “Le chat mange du poisson” (which means “The cat eats fish” in English), and the output sentence in English is “The cat eats fish”. We want to build a neural machine translation model that takes the French sentence as input and produces the English sentence as output.</p>

<p>The first step is to represent the input sentence as a sequence of vectors. We can use a word embedding matrix to represent each word in the sentence as a vector. For simplicity, let’s assume that each word is represented as a 3-dimensional vector. Then, the input sentence can be represented as a matrix X of shape (5,3), where each row corresponds to a word vector:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
<span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
<span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
<span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">],</span>
<span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]]</span>
</code></pre></div></div>

<p>Next, we need to define the query vector q, which represents the context of the output sentence that we want to generate. For simplicity, let’s assume that the output sentence has a fixed length of 4 words, and each word is represented as a 3-dimensional vector. Then, the query vector q can be represented as a matrix of shape (4,3), where each row corresponds to a word vector:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">q</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="p">],</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
<span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">],</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]]</span>
</code></pre></div></div>

<p>Now, we can compute the attention scores using the dot product attention. For each row of q, we compute the dot product with each row of X:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">q</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
</code></pre></div></div>

<p>The resulting matrix s contains the attention scores for each word in the input sentence and each word in the output sentence:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.24</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.26</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">],</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.22</span><span class="p">,</span> <span class="mf">0.14</span><span class="p">,</span> <span class="mf">0.16</span><span class="p">],</span>
<span class="p">[</span> <span class="mf">0.01</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.34</span><span class="p">,</span> <span class="mf">0.34</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.26</span><span class="p">],</span>
<span class="p">[</span><span class="o">-</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.37</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.18</span><span class="p">],</span>
<span class="p">[</span> <span class="mf">0.07</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.22</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14</span><span class="p">]]</span>
</code></pre></div></div>

<p>To convert the attention scores into attention weights, we need to apply the softmax function to each column of s:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">alpha</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<p>The resulting matrix alpha contains the attention weights for each word in the input sentence and each word in the output sentence:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">alpha</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.3218</span><span class="p">,</span> <span class="mf">0.2411</span><span class="p">,</span> <span class="mf">0.1202</span><span class="p">,</span> <span class="mf">0.3057</span><span class="p">],</span>
<span class="p">[</span><span class="mf">0.2586</span><span class="p">,</span> <span class="mf">0.2142</span><span class="p">,</span> <span class="mf">0.2679</span><span class="p">,</span> <span class="mf">0.3319</span><span class="p">],</span>
<span class="p">[</span><span class="mf">0.2857</span><span class="p">,</span> <span class="mf">0.1693</span><span class="p">,</span> <span class="mf">0.3423</span><span class="p">,</span> <span class="mf">0.1809</span><span class="p">],</span>
<span class="p">[</span><span class="mf">0.2784</span><span class="p">,</span> <span class="mf">0.2414</span><span class="p">,</span> <span class="mf">0.1356</span><span class="p">,</span> <span class="mf">0.3422</span><span class="p">],</span>
<span class="p">[</span><span class="mf">0.3055</span><span class="p">,</span> <span class="mf">0.1340</span><span class="p">,</span> <span class="mf">0.1340</span><span class="p">,</span> <span class="mf">0.2193</span><span class="p">]]</span>
</code></pre></div></div>

<p>Finally, we can compute the context vectors by taking the weighted sum of the input vectors for each word in the output sentence. The context vectors can be computed as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">alpha</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</code></pre></div></div>

<p>The resulting matrix C contains the attended information from the input sentence for each word in the output sentence:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">C</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">0.1866</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0502</span><span class="p">,</span> <span class="mf">0.4296</span><span class="p">],</span>
<span class="p">[</span> <span class="mf">0.0815</span><span class="p">,</span> <span class="mf">0.0269</span><span class="p">,</span> <span class="mf">0.2632</span><span class="p">],</span>
<span class="p">[</span> <span class="mf">0.1333</span><span class="p">,</span> <span class="mf">0.0125</span><span class="p">,</span> <span class="mf">0.3869</span><span class="p">],</span>
<span class="p">[</span> <span class="mf">0.1621</span><span class="p">,</span> <span class="mf">0.0738</span><span class="p">,</span> <span class="mf">0.1943</span><span class="p">]]</span>
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>In this blog post, we explained the attention mechanism in detail, including the mathematical expressions and formulas. We also provided a full numerical example to illustrate how attention works in practice. Attention mechanisms have become an essential tool in deep learning, particularly in NLP, and have led to significant improvements in model performance. Understanding attention mechanisms is crucial for building state-of-the-art deep learning models and pushing the boundaries of AI research.</p>


		</article>

	</div>

</section>

		</div>

	</div>


	<footer class="footer">

	<div class="wrap">

		<p class="footer__text"></p>

		<div class="footer__copyright">
			<span>© 2023 ML with Ramin</span>
			<a href="https://jekyllthemes.io" target="_blank">Jekyll Themes</a>
		</div>

		<ul class="socials">
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	<li class="socials__item">
		<a href="https://medium.com/@mohammadi.r" target="_blank" class="socials__item__link" title="Medium">
			<i class="fab fa-medium" aria-hidden="true"></i>
		</a>
	</li>
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	<li class="socials__item">
		<a href="https://www.linkedin.com/in/ramin-mohammadi-ml/" target="_blank" class="socials__item__link" title="Linkedin">
			<i class="fab fa-linkedin" aria-hidden="true"></i>
		</a>
	</li>
	
	
</ul>

	</div>

</footer>


	<!-- Javascript Assets -->
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script src="/js/plugins-min.js"></script>
	<script src="/js/personal-min.js"></script>

	
	<!-- Extra Footer JS Code -->
	
	


</body>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>


</html>